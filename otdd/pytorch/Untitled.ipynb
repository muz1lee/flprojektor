{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a55cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# general\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import itertools\n",
    "from scipy.special import comb\n",
    "from cvxopt import matrix, solvers, spdiag\n",
    "import copy\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import os\n",
    "\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Keras / Tensorflow Libraries\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, LeakyReLU, Dropout, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow.keras.utils as np_utils\n",
    "import tensorflow\n",
    "\n",
    "from utility_functions import *\n",
    "from pubfig83_utility import *\n",
    "from deepset import *\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "def getSelectedAcc(rank, target_size, x_train, y_train, x_val, y_val, utilityFunc, interval=50):\n",
    "  if rank is None or utilityFunc is None:\n",
    "    return None\n",
    "  ret = np.zeros(int(target_size/interval))\n",
    "  for i in range(1, int(target_size/interval)+1):\n",
    "    ret[i-1] = utilityFunc(x_train[rank[::-1][interval*(i):]], y_train[rank[::-1][interval*(i):]], x_val, y_val)\n",
    "  return ret\n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "parser = argparse.ArgumentParser('')\n",
    "\n",
    "parser.add_argument('--attack_type', type=str)\n",
    "\n",
    "parser.add_argument('--lc', action='store_true')\n",
    "parser.add_argument('--sv', action='store_true')\n",
    "parser.add_argument('--loo', action='store_true')\n",
    "parser.add_argument('--tmc', action='store_true')\n",
    "parser.add_argument('--gshap', action='store_true')\n",
    "parser.add_argument('--inf', action='store_true')\n",
    "parser.add_argument('--tracin_self', action='store_true')\n",
    "parser.add_argument('--tracin_clean', action='store_true')\n",
    "parser.add_argument('--knn', action='store_true')\n",
    "parser.add_argument('--deepset', action='store_true')\n",
    "parser.add_argument('--random', action='store_true')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "rank_coll_dir = 'rank-collections/'\n",
    "\n",
    "\n",
    "post_fix = ''\n",
    "if args.lc:\n",
    "  post_fix += 'LC_'\n",
    "if args.sv:\n",
    "  post_fix += 'SV_'\n",
    "if args.loo:\n",
    "  post_fix += 'LOO_'\n",
    "if args.tmc:\n",
    "  post_fix += 'TMC_'\n",
    "if args.gshap:\n",
    "  post_fix += 'GSHAP_'\n",
    "if args.inf:\n",
    "  post_fix += 'INF_'\n",
    "if args.tracin_self:\n",
    "  post_fix += 'TRACINSELF_'\n",
    "if args.tracin_clean:\n",
    "  post_fix += 'TRACINCLEAN_'\n",
    "if args.knn:\n",
    "  post_fix += 'KNN_'\n",
    "if args.random:\n",
    "  post_fix += 'RANDOM_'\n",
    "if args.deepset:\n",
    "  post_fix += 'DEEPSET'\n",
    "\n",
    "\n",
    "print('POST FIX:', post_fix)\n",
    "\n",
    "attack_type = args.attack_type\n",
    "\n",
    "\n",
    "\n",
    "if attack_type == 'CIFAR_Backdoor':\n",
    "\n",
    "  data_file = 'backdoor_cifar_N50000_poison2500_val1000.data'\n",
    "  x_train_few, y_train_few, x_val_poi, y_val_poi, x_val, y_val = pickle.load( \n",
    "    open('low-quality-data/'+data_file, 'rb') )\n",
    "\n",
    "  y_train_few = y_train_few.reshape(-1)\n",
    "  y_val_poi = y_val_poi.reshape(-1)\n",
    "  y_val = y_val.reshape(-1)\n",
    "\n",
    "  n_data_deepset = 2000\n",
    "  n_epoch = 16\n",
    "  n_set = 64\n",
    "  n_hext = 64\n",
    "  n_hreg = 64\n",
    "  LR = 1e-4\n",
    "\n",
    "  deepset_dir = 'saved-deepset/Rebuttal_Backdoor_CIFAR_N{}_DataSeed100_Nepoch{}_Nset{}_Next{}_Nreg{}_LR{}.state_dict'.format(\n",
    "    n_data_deepset, n_epoch, n_set, n_hext, n_hreg, LR)\n",
    "\n",
    "  func_data_to_acc = None\n",
    "  # func_data_to_atkacc = torch_cifar_smallCNN_data_to_acc_multiple\n",
    "  func_data_to_atkacc = torch_cifar_vit_data_to_acc\n",
    "\n",
    "\n",
    "elif attack_type == '...'\n",
    "\n",
    "\n",
    "\n",
    "acc_coll_dir = rank_coll_dir+'ICMLRebuttal2_{}_{}.acccoll'.format(attack_type, post_fix)\n",
    "\n",
    "#x_train_few, y_train_few = x_train_few[:n_data_deepset], y_train_few[:n_data_deepset]\n",
    "\n",
    "n_data = x_train_few.shape[0]\n",
    "target_size = x_train_few.shape[0]\n",
    "\n",
    "\n",
    "if args.inf:\n",
    "\n",
    "  [score] = pickle.load( open(\"saved-samples/ICML_{}_INF.sample\".format(attack_type), 'rb') )\n",
    "  inf_rank = np.argsort(score)\n",
    "\n",
    "if args.tracin_self:\n",
    "\n",
    "  [score] = pickle.load( open(\"saved-samples/ICML_{}_TRACINSELF.sample\".format(attack_type), 'rb') )\n",
    "  tracinself_rank = np.argsort(score)[::-1]\n",
    "\n",
    "if args.tracin_clean:\n",
    "\n",
    "  [score] = pickle.load( open(\"saved-samples/ICML_{}_TRACINCLEAN.sample\".format(attack_type), 'rb') )\n",
    "  tracinclean_rank = np.argsort(score)\n",
    "\n",
    "if args.knn:\n",
    "\n",
    "  [score] = pickle.load( open(\"saved-samples/ICML_{}_KNN.sample\".format(attack_type), 'rb') )\n",
    "  knn_rank = np.argsort(score)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if not args.lc:\n",
    "  lc_rank = None\n",
    "if not args.sv:\n",
    "  sv_rank = None\n",
    "if not args.loo:\n",
    "  loo_rank = None\n",
    "if not args.tmc:\n",
    "  tmc_rank = None\n",
    "if not args.gshap:\n",
    "  gshap_rank = None\n",
    "if not args.inf:\n",
    "  inf_rank = None\n",
    "if not args.tracin_self:\n",
    "  tracinself_rank = None\n",
    "if not args.tracin_clean:\n",
    "  tracinclean_rank = None\n",
    "if not args.knn:\n",
    "  knn_rank = None\n",
    "if not args.deepset:\n",
    "  deepset_rank = None\n",
    "if not args.random:\n",
    "  random_rank = None\n",
    "\n",
    "\n",
    "if args.deepset:\n",
    "\n",
    "  if attack_type=='CIFAR_Mislabel' or attack_type=='CIFAR_Poison' or attack_type=='CIFAR_Noisy':\n",
    "    opt = tf.train.AdamOptimizer()\n",
    "    extractor = CifarExtractor.build(numChannels=3, imgRows=32, imgCols=32, numClasses=10)\n",
    "    extractor.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    load_status = extractor.load_weights('cifar_featureExtractor.ckpt')\n",
    "    lastLayerOp = K.function([extractor.layers[0].input], [extractor.layers[-5].output])\n",
    "    x_train_few_cnnFeature = extractFeatures(lastLayerOp, x_train_few)\n",
    "\n",
    "    print('FeatureExtractor', x_train_few_cnnFeature.shape)\n",
    "\n",
    "    n_cls = 10\n",
    "    eps = 1e-3\n",
    "\n",
    "    if len(y_train_few.shape) < 2 or y_train_few.shape[1]!=10:\n",
    "      y_train_few_hot = np_utils.to_categorical(y_train_few, 10)\n",
    "    else:\n",
    "      y_train_few_hot = y_train_few\n",
    "\n",
    "  elif attack_type[:5]=='CIFAR' or attack_type[:6]=='DOGCAT':\n",
    "\n",
    "    extractor_savename = 'saved-deepset/Rebuttal_Backdoor_CIFAR_Extractor.state_dict'\n",
    "\n",
    "    extractor = SmallCNN_CIFAR().cuda()\n",
    "    extractor.load_state_dict( torch.load( extractor_savename ) )\n",
    "\n",
    "    if x_train_few.shape[1]==32:\n",
    "        x_train_few_cf = np.moveaxis(x_train_few, 3, 1)\n",
    "    tensor_x = torch.Tensor(x_train_few_cf).cuda()\n",
    "    x_train_few_cnnFeature = extractor.getFeature(tensor_x)\n",
    "    x_train_few_cnnFeature = x_train_few_cnnFeature.cpu().detach().numpy()\n",
    "\n",
    "    print('FeatureExtractor', x_train_few_cnnFeature.shape)\n",
    "\n",
    "    n_cls = 10\n",
    "    eps = 1e-3\n",
    "\n",
    "    if len(y_train_few.shape) < 2 or y_train_few.shape[1]!=10:\n",
    "      y_train_few_hot = np_utils.to_categorical(y_train_few, 10)\n",
    "    else:\n",
    "      y_train_few_hot = y_train_few\n",
    "\n",
    "\n",
    "  elif attack_type[:4]=='SPAM':\n",
    "\n",
    "    from sklearn.feature_selection import SelectPercentile\n",
    "    from sklearn.feature_selection import chi2\n",
    "    selector = SelectPercentile(score_func=chi2, percentile=10)\n",
    "    x_train_few_cnnFeature = selector.fit_transform(x_train_clean, y_train_clean)\n",
    "    x_train_few_cnnFeature = x_train_few_cnnFeature[train_ind]\n",
    "    n_cls = 2\n",
    "    y_train_few_hot = y_train_few.reshape((len(y_train_few), 1))\n",
    "\n",
    "    eps = 1e-3\n",
    "\n",
    "\n",
    "  elif attack_type[:5]=='MNIST':\n",
    "    opt = tf.train.AdamOptimizer()\n",
    "    extractor = KerasLeNet.build(numChannels=1, imgRows=28, imgCols=28, numClasses=10)\n",
    "    extractor.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    load_status = extractor.load_weights('mnist_featureExtractor.h5')\n",
    "    lastLayerOp = K.function([extractor.layers[0].input], [extractor.layers[6].output])\n",
    "    x_train_few_cnnFeature = extractFeatures(lastLayerOp, x_train_few)\n",
    "    n_cls = 10\n",
    "    eps = 1e-3\n",
    "\n",
    "    if len(y_train_few.shape) < 2 or y_train_few.shape[1]!=10:\n",
    "      y_train_few_hot = np_utils.to_categorical(y_train_few, 10)\n",
    "    else:\n",
    "      y_train_few_hot = y_train_few\n",
    "\n",
    "\n",
    "  elif attack_type[:6]=='PUBFIG':\n",
    "    opt = tf.train.AdamOptimizer()\n",
    "    extractor = CifarExtractor.build(numChannels=3, imgRows=32, imgCols=32, numClasses=83)\n",
    "    extractor.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    load_status = extractor.load_weights('pubfig_featureExtractor.h5')\n",
    "    lastLayerOp = K.function([extractor.layers[0].input], [extractor.layers[-5].output])\n",
    "    x_train_few_cnnFeature = extractFeatures(lastLayerOp, x_train_few)\n",
    "\n",
    "    n_cls = 83\n",
    "    y_train_few_hot = np_utils.to_categorical(y_train_few)\n",
    "    eps = 1e-3\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "deepset_rank_coll = np.zeros((10, n_data))\n",
    "random_rank_coll = np.zeros((10, n_data))\n",
    "acc_coll = {}\n",
    "atkacc_coll = {}\n",
    "\n",
    "acc_coll['deepset'] = []\n",
    "acc_coll['lc'] = []\n",
    "acc_coll['sv'] = []\n",
    "acc_coll['loo'] = []\n",
    "acc_coll['tmc'] = []\n",
    "acc_coll['gshap'] = []\n",
    "acc_coll['inf'] = []\n",
    "acc_coll['tracinself'] = []\n",
    "acc_coll['tracinclean'] = []\n",
    "acc_coll['knn'] = []\n",
    "acc_coll['random'] = []\n",
    "\n",
    "atkacc_coll['deepset'] = []\n",
    "atkacc_coll['lc'] = []\n",
    "atkacc_coll['sv'] = []\n",
    "atkacc_coll['loo'] = []\n",
    "atkacc_coll['tmc'] = []\n",
    "atkacc_coll['gshap'] = []\n",
    "atkacc_coll['inf'] = []\n",
    "atkacc_coll['tracinself'] = []\n",
    "atkacc_coll['tracinclean'] = []\n",
    "atkacc_coll['knn'] = []\n",
    "atkacc_coll['random'] = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load (x_bad, y_bad)\n",
    "# Load Data Utility Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for select_seed in range(10):\n",
    "#for select_seed in range(1):\n",
    "\n",
    "  if args.deepset and attack_type[:6]!='PUBFIG':\n",
    "\n",
    "    n_block = int(n_data/n_data_deepset)\n",
    "    deepset_rank_matrix = np.zeros((n_block, n_data_deepset))\n",
    "    random_perm = np.random.permutation(range(n_data))\n",
    "\n",
    "    for i in range(n_block):\n",
    "      \n",
    "      random_ind = random_perm[n_data_deepset*(i):n_data_deepset*(i+1)]\n",
    "\n",
    "      if attack_type == 'MNIST_Noisy':\n",
    "\n",
    "        _, deepset_rank_small, _ = findMostValuableSample_deepset_stochasticgreedy_OLD(deepset_model.model, \n",
    "                                                                                       x_train_few_cnnFeature[random_ind], \n",
    "                                                                                       n_data_deepset, epsilon=eps, seed=select_seed)\n",
    "      else:\n",
    "        _, deepset_rank_small, _ , _ = findMostValuableSample_deepset_stochasticgreedy(deepset_model.model, \n",
    "                                                                                       x_train_few_cnnFeature[random_ind], \n",
    "                                                                                       y_train_few_hot[random_ind], \n",
    "                                                                                       n_data_deepset, epsilon=eps, seed=select_seed)\n",
    "\n",
    "      deepset_rank_matrix[i] = random_ind[deepset_rank_small]\n",
    "\n",
    "    deepset_rank = ((deepset_rank_matrix.T).reshape(-1)).astype(int)\n",
    "    deepset_rank_coll[select_seed] = deepset_rank\n",
    "\n",
    "  if args.random:\n",
    "    random_rank = np.random.permutation(range(n_data))\n",
    "    random_rank_coll[select_seed] = random_rank\n",
    "\n",
    "  if args.deepset and attack_type[:6]=='PUBFIG':\n",
    "    deepset_rank = np.random.permutation(range(n_data))\n",
    "    deepset_rank_coll[select_seed] = deepset_rank\n",
    "\n",
    "\n",
    "  half_size = int(target_size / 2)\n",
    "  interval = int(half_size / 10)\n",
    "  # interval = int(half_size / 5)\n",
    "\n",
    "  print('Select Seed', select_seed)\n",
    "\n",
    "  deepset_acc = getSelectedAcc(deepset_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)  \n",
    "  \n",
    "  lc_acc = getSelectedAcc(lc_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  sv_acc = getSelectedAcc(sv_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  loo_acc = getSelectedAcc(loo_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  tmc_acc = getSelectedAcc(tmc_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  gshap_acc = getSelectedAcc(gshap_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  inf_acc = getSelectedAcc(inf_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  tracinself_acc = getSelectedAcc(tracinself_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  tracinclean_acc = getSelectedAcc(tracinclean_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  \n",
    "  knn_acc = getSelectedAcc(knn_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "  \n",
    "  # random_acc = getSelectedAcc(random_rank, half_size, x_train_few, y_train_few, x_val, y_val, func_data_to_acc, interval)\n",
    "\n",
    "  acc_coll['deepset'].append(deepset_acc)\n",
    "  acc_coll['lc'].append(lc_acc)\n",
    "  acc_coll['sv'].append(sv_acc)\n",
    "  acc_coll['loo'].append(loo_acc)\n",
    "  acc_coll['tmc'].append(tmc_acc)\n",
    "  acc_coll['gshap'].append(gshap_acc)\n",
    "  acc_coll['inf'].append(inf_acc)\n",
    "  acc_coll['tracinself'].append(tracinself_acc)\n",
    "  acc_coll['tracinclean'].append(tracinclean_acc)\n",
    "  acc_coll['knn'].append(knn_acc)\n",
    "  acc_coll['random'].append(random_acc)\n",
    "\n",
    "  deepset_acc = getSelectedAcc(deepset_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  lc_acc = getSelectedAcc(lc_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  sv_acc = getSelectedAcc(sv_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  loo_acc = getSelectedAcc(loo_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  tmc_acc = getSelectedAcc(tmc_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  gshap_acc = getSelectedAcc(gshap_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  inf_acc = getSelectedAcc(inf_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  tracinself_acc = getSelectedAcc(tracinself_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  tracinclean_acc = getSelectedAcc(tracinclean_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  knn_acc = getSelectedAcc(knn_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "  random_acc = getSelectedAcc(random_rank, half_size, x_train_few, y_train_few, x_val_poi, y_val_poi, func_data_to_atkacc, interval)\n",
    "\n",
    "  atkacc_coll['deepset'].append(deepset_acc)\n",
    "  atkacc_coll['lc'].append(lc_acc)\n",
    "  atkacc_coll['sv'].append(sv_acc)\n",
    "  atkacc_coll['loo'].append(loo_acc)\n",
    "  atkacc_coll['tmc'].append(tmc_acc)\n",
    "  atkacc_coll['gshap'].append(gshap_acc)\n",
    "  atkacc_coll['inf'].append(inf_acc)\n",
    "  atkacc_coll['tracinself'].append(tracinself_acc)\n",
    "  atkacc_coll['tracinclean'].append(tracinclean_acc)\n",
    "  atkacc_coll['knn'].append(knn_acc)\n",
    "  atkacc_coll['random'].append(random_acc)\n",
    "\n",
    "  pickle.dump([deepset_rank_coll, random_rank_coll, acc_coll, atkacc_coll], open(acc_coll_dir, 'wb') )\n",
    "\n",
    "  print('save!!!')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
